{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "from itertools import product, count\n",
    "from string import punctuation\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english') + list(punctuation))\n",
    "max_cut = 0.9\n",
    "min_cut = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_frequencies(word_sent):\n",
    "\n",
    "    freq = defaultdict(int)\n",
    "\n",
    "    for s in word_sent:\n",
    "        for word in s:\n",
    "\n",
    "            if word not in stopwords:\n",
    "                freq[word] += 1\n",
    "\n",
    "    m = float(max(freq.values()))\n",
    "    \n",
    "    for w in list(freq.keys()):\n",
    "        freq[w] = freq[w]/m\n",
    "        if freq[w] >= max_cut or freq[w] <= min_cut:\n",
    "            del freq[w]\n",
    "    \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text, n):\n",
    "    \n",
    "    sents = sent_tokenize(text)\n",
    "    assert n <= len(sents)\n",
    "\n",
    "    word_sent = [word_tokenize(s.lower()) for s in sents]\n",
    "\n",
    "    freq = compute_frequencies(word_sent)\n",
    "    ranking = defaultdict(int)\n",
    "    for i, word in enumerate(word_sent):\n",
    "        for w in word:\n",
    "            if w in freq:\n",
    "                ranking[i] += freq[w]\n",
    "    sents_idx = rank(ranking, n)\n",
    "    return [sents[j] for j in sents_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(ranking, n):\n",
    "    return nlargest(n, ranking, key=ranking.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Modern life is dramatically different to even 30 years ago,\" Prof Gray told Radio 4's Today programme, \"people now drive to work and sit at work.\"\n",
      "\"The How Are You Quiz will help anyone who wants to take a few minutes to take stock and find out quickly where they can take a little action to make a big difference to their health.\"\n"
     ]
    }
   ],
   "source": [
    "with open(\"news.txt\", \"r\") as myfile:\n",
    "    text = myfile.read().replace('\\n','')\n",
    "res = summarize(text, 2)\n",
    "for i in range(len(res)):\n",
    "    print(res[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english') + list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(sen1, sen2):\n",
    "\n",
    "    counter = 0\n",
    "    for word in sen1:\n",
    "        if word in sen2:\n",
    "            counter += 1\n",
    "    return counter / (math.log(len(sen1)) + math.log(len(sen2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(word_sent):\n",
    "    num = len(word_sent)\n",
    "    \n",
    "    board = [[0.0 for _ in range(num)] for _ in range(num)]\n",
    "\n",
    "    for i, j in product(range(num), repeat=2):\n",
    "        if i != j:\n",
    "            board[i][j] = calculate_similarity(word_sent[i], word_sent[j])\n",
    "    return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_pagerank(weight_graph):\n",
    "\n",
    "    scores = [0.5 for _ in range(len(weight_graph))]\n",
    "    old_scores = [0.0 for _ in range(len(weight_graph))]\n",
    "\n",
    "    while different(scores, old_scores):\n",
    "        for i in range(len(weight_graph)):\n",
    "            old_scores[i] = scores[i]\n",
    "\n",
    "        for i in range(len(weight_graph)):\n",
    "            scores[i] = calculate_score(weight_graph, scores, i)\n",
    "    return scores\n",
    "\n",
    "def different(scores, old_scores):\n",
    "    flag = False\n",
    "    for i in range(len(scores)):\n",
    "        if math.fabs(scores[i] - old_scores[i]) >= 0.0001:\n",
    "            flag = True\n",
    "            break\n",
    "    return flag\n",
    "\n",
    "def calculate_score(weight_graph, scores, i):\n",
    "    length = len(weight_graph)\n",
    "    d = 0.85\n",
    "    added_score = 0.0\n",
    "\n",
    "    for j in range(length):\n",
    "        fraction = 0.0\n",
    "        denominator = 0.0\n",
    "        \n",
    "        fraction = weight_graph[j][i] * scores[j]\n",
    "        \n",
    "        for k in range(length):\n",
    "            denominator += weight_graph[j][k]\n",
    "        added_score += fraction / denominator\n",
    "    \n",
    "    weighted_score = (1 - d) + d * added_score\n",
    "\n",
    "    return weighted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Summarize(text,n):\n",
    "    \n",
    "    sents = sent_tokenize(text)\n",
    "    \n",
    "    word_sent = [word_tokenize(s.lower()) for s in sents]\n",
    "\n",
    "    for i in range(len(word_sent)):\n",
    "        for word in word_sent[i]:\n",
    "            if word in stopwords:\n",
    "                word_sent[i].remove(word)\n",
    "    similarity_graph = create_graph(word_sent)\n",
    "    scores = weighted_pagerank(similarity_graph)\n",
    "    sent_selected = nlargest(n, zip(scores, count()))\n",
    "    sent_index = []\n",
    "    for i in range(n):\n",
    "        sent_index.append(sent_selected[i][1])\n",
    "    return [sents[i] for i in sent_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The PHE website and app has a quiz that gives users a health score based on their lifestyle habits by asking questions such as, \"Which snacks do you eat in a normal day?\"', 'The campaign\\'s clinical adviser, Prof Muir Gray, said it was about trying to make people have a different attitude to an \"environmental problem\".']\n"
     ]
    }
   ],
   "source": [
    "with open(\"news.txt\", \"r\") as myfile:\n",
    "    text = myfile.read().replace('\\n' , '')\n",
    "    \n",
    "print(Summarize(text, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
